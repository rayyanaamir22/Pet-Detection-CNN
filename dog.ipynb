{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Detection CNN Model\n",
    "\n",
    "Attempt to get my friend's attention by making them use this on their dog. Practicing with TensorFlow is nice too, I guess.\n",
    "\n",
    "#BornToUseCamelCase_forced_to_use_snake_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Prepare the dataset\n",
    "\n",
    "We will be using the Stanford dogs Image Dataset from Roboflow. It contains 23 223 jpg images of dogs, labelled with bounding boxes. It's too large to commit, so you'll have to download it manually, and add it to this directory. You can download it from the site here: https://universe.roboflow.com/igor-romanica-gmail-com/stanford-dogs-0pff9. Make sure to select the Tensorflow Object Detection CSV format.\n",
    "\n",
    "Once that's done, we can parse the data into a keras Sequence object that will serve as our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Data Generator Object. Inherits from tf.keras.utils.Sequence\n",
    "\n",
    "    >>> batch_size = 32\n",
    "    >>> image_size = (224, 224)\n",
    "    >>> image_dir = 'path/to/your/dataset/images'\n",
    "    >>> annotation_file = 'path/to/your/dataset/annotations.csv'\n",
    "    >>> dataset = DataGenerator(image_dir, annotation_file, batch_size, image_size)\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file, image_dir, batch_size, image_size):\n",
    "        \"\"\"\n",
    "        DataGenerator constructor method.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.num_samples = len(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.num_samples / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_data = self.data.iloc[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        images = []\n",
    "        annotations = []\n",
    "\n",
    "        for _, row in batch_data.iterrows():\n",
    "            image_path = row['image_path']\n",
    "            image = cv2.imread(os.path.join(self.image_dir, image_path))\n",
    "            image = cv2.resize(image, self.image_size)\n",
    "            image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "            xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n",
    "            class_label = row['class_label']\n",
    "\n",
    "            # You may need to convert the coordinates to relative values or other formats as per your requirements\n",
    "\n",
    "            images.append(image)\n",
    "            annotations.append((xmin, ymin, xmax, ymax, class_label))\n",
    "\n",
    "        return np.array(images), np.array(annotations)\n",
    "\n",
    "        return np.array(images), np.array(annotations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
