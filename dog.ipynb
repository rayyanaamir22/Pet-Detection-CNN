{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Detection CNN Model\n",
    "\n",
    "Attempt to get my friend's attention by making them use this on their dog. Practicing with TensorFlow is nice too, I guess.\n",
    "\n",
    "#BornToUseCamelCase_forced_to_use_snake_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Prepare the dataset\n",
    "\n",
    "We will be using the Stanford dogs Image Dataset from Roboflow. It contains 23 223 jpg images of dogs, labelled with bounding boxes. It's too large to commit, so you'll have to download it manually, and add it to this directory. You can download it from the site here: https://universe.roboflow.com/igor-romanica-gmail-com/stanford-dogs-0pff9. Make sure to select the Tensorflow Object Detection CSV format.\n",
    "\n",
    "Once that's done, we can parse the data into a keras Sequence object that will serve as our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Data Generator class. Inherits from tf.keras.utils.Sequence\n",
    "\n",
    "    >>> batch_size = 32\n",
    "    >>> image_size = (224, 224)\n",
    "    >>> csv_file = 'path/to/your/annotations.csv'\n",
    "    >>> image_dir = 'path/to/your/images'\n",
    "    >>> data_generator = CustomDataGenerator(csv_file, image_dir, batch_size, image_size)\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file: str, image_dir: str, batch_size: int, image_size: tuple[int, int]) -> None:\n",
    "        \"\"\"\n",
    "        DataGenerator constructor method.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.num_samples = len(self.data)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int(np.ceil(self.num_samples / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[np.array, np.array]:\n",
    "        batch_data = self.data.iloc[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        images = []\n",
    "        annotations = []\n",
    "\n",
    "        for _, row in batch_data.iterrows():\n",
    "            image_path = row['image_path']\n",
    "            image = cv2.imread(os.path.join(self.image_dir, image_path))\n",
    "            image = cv2.resize(image, self.image_size)\n",
    "            image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "            xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n",
    "            class_label = row['class_label']\n",
    "\n",
    "            # You may need to convert the coordinates to relative values or other formats as per your requirements\n",
    "\n",
    "            images.append(image)\n",
    "            annotations.append((xmin, ymin, xmax, ymax, class_label))\n",
    "\n",
    "        return np.array(images), np.array(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train, test, and validation datasets\n",
    "X_train = DataGenerator(\n",
    "    os.getcwd() + \"/Stanford dogs.v3i.tensorflow/train/_annotations.csv\",\n",
    "    os.getcwd() + \"/Stanford dogs.v3i.tensorflow/train\",\n",
    "    32,\n",
    "    (224, 224)\n",
    ")\n",
    "X_test = DataGenerator(\n",
    "    os.getcwd() + \"/Stanford dogs.v3i.tensorflow/test/_annotations.csv\",\n",
    "    os.getcwd() + \"/Stanford dogs.v3i.tensorflow/test\",\n",
    "    32,\n",
    "    (224, 224)\n",
    ")\n",
    "X_valid = DataGenerator(\n",
    "    os.getcwd() + \"/Stanford dogs.v3i.tensorflow/valid/_annotations.csv\",\n",
    "    os.getcwd() + \"/Stanford dogs.v3i.tensorflow/valid\",\n",
    "    32,\n",
    "    (224, 224)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n02101388_1941_jpg.rf.3c607af1ab5a273782f4571c...</td>\n",
       "      <td>416</td>\n",
       "      <td>416</td>\n",
       "      <td>Brittany_spaniel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n02110627_8949_jpg.rf.3c46c1369619b5bb5cfdb3a1...</td>\n",
       "      <td>416</td>\n",
       "      <td>416</td>\n",
       "      <td>affenpinscher</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>357</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n02104365_8466_jpg.rf.3c5461b0f06c5f16c429325a...</td>\n",
       "      <td>416</td>\n",
       "      <td>416</td>\n",
       "      <td>schipperke</td>\n",
       "      <td>82</td>\n",
       "      <td>28</td>\n",
       "      <td>310</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n02110627_8048_jpg.rf.3c48c2201000f8ff85d61771...</td>\n",
       "      <td>416</td>\n",
       "      <td>416</td>\n",
       "      <td>affenpinscher</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n02100877_239_jpg.rf.3c5813c61b445e08fff6c09b4...</td>\n",
       "      <td>416</td>\n",
       "      <td>416</td>\n",
       "      <td>Irish_setter</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>411</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  width  height   \n",
       "0  n02101388_1941_jpg.rf.3c607af1ab5a273782f4571c...    416     416  \\\n",
       "1  n02110627_8949_jpg.rf.3c46c1369619b5bb5cfdb3a1...    416     416   \n",
       "2  n02104365_8466_jpg.rf.3c5461b0f06c5f16c429325a...    416     416   \n",
       "3  n02110627_8048_jpg.rf.3c48c2201000f8ff85d61771...    416     416   \n",
       "4  n02100877_239_jpg.rf.3c5813c61b445e08fff6c09b4...    416     416   \n",
       "\n",
       "              class  xmin  ymin  xmax  ymax  \n",
       "0  Brittany_spaniel     0     0   416   393  \n",
       "1     affenpinscher    56     5   357   416  \n",
       "2        schipperke    82    28   310   416  \n",
       "3     affenpinscher     0     0   394   413  \n",
       "4      Irish_setter    28     5   411   416  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that data loaded properly\n",
    "X_train.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'image_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image_path'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# View an image from the first batch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sample_batch, annotations \u001b[39m=\u001b[39m X_train[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m      3\u001b[0m \u001b[39m# select an image\u001b[39;00m\n\u001b[1;32m      4\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39m# 0 <= i <= batch_size - 1\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m, in \u001b[0;36mDataGenerator.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     28\u001b[0m annotations \u001b[39m=\u001b[39m []\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m _, row \u001b[39min\u001b[39;00m batch_data\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m---> 31\u001b[0m     image_path \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39;49m\u001b[39mimage_path\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m     32\u001b[0m     image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_dir, image_path))\n\u001b[1;32m     33\u001b[0m     image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(image, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_size)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:1012\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1011\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1012\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1014\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1015\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1017\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1120\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1121\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1123\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image_path'"
     ]
    }
   ],
   "source": [
    "# View an image from the first batch\n",
    "sample_batch, annotations = X_train[0]\n",
    "# select an image\n",
    "i = 0 # 0 <= i <= batch_size - 1\n",
    "sample_image, sample_annotation = sample_batch[i], annotations[i]\n",
    "plt.imshow(sample_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
